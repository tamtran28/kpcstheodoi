import streamlit as st
import pandas as pd
import docx
import re
import pytesseract
from PIL import Image
import io

# ===========================================
# ========== MODULE Xá»¬ LÃ KPCS ==============
# ===========================================

def extract_r2_from_heading(text):
    """
    Tá»± Ä‘á»™ng nháº­n tiÃªu Ä‘á» dáº¡ng 1.1 / 2.1 / 3.1 â†’ TÃªn phÃ¡t hiá»‡n (R2)
    """
    pattern = r"(\d+\.\d+)\s*[-:]?\s*(.*)"
    m = re.match(pattern, text.strip())
    if m:
        return m.group(2).strip()
    return text


def extract_word_paragraphs(doc):
    """
    Láº¥y toÃ n bá»™ Ä‘oáº¡n tá»« Word (khÃ´ng OCR)
    """
    return [p.text.strip() for p in doc.paragraphs if p.text.strip()]


def extract_images_from_word(doc):
    """
    TrÃ­ch áº£nh tá»« file Word Ä‘á»ƒ Ä‘Æ°a OCR
    """
    images = []
    rels = doc.part.rels

    for rel in rels:
        if "image" in rels[rel].target_ref:
            img = rels[rel]._target.blob
            images.append(Image.open(io.BytesIO(img)))

    return images


def run_ocr_on_images(images):
    """
    OCR toÃ n bá»™ áº£nh â†’ tráº£ vá» text
    """
    text_blocks = []
    for img in images:
        text = pytesseract.image_to_string(img, lang="vie+eng")
        text_blocks.append(text)
    return text_blocks


def extract_4_regions(paragraphs, ocr_blocks):
    """
    TÃ¡ch 4 vÃ¹ng theo yÃªu cáº§u:
    1. R0 â€“ R1
    2. R3
    3. MÃ´ táº£ chi tiáº¿t
    4. Dáº«n chiáº¿u
    CÃ¡c vÃ¹ng cÃ²n láº¡i láº¥y tá»« mark gáº¡ch chÃ¢n / khoanh trÃ²n trong OCR
    """

    r0_r1, r3, mo_ta, dan_chieu = "", "", "", ""

    # láº¥y cÃ¡c vÃ¹ng tá»« Word
    for p in paragraphs:
        if "Nghiá»‡p vá»¥" in p or "R0" in p:
            r0_r1 = p
        elif "Chi tiáº¿t phÃ¡t hiá»‡n" in p or "R3" in p:
            r3 = p
        elif "MÃ´ táº£ chi tiáº¿t" in p:
            mo_ta = p
        elif "Dáº«n chiáº¿u" in p:
            dan_chieu = p

    # OCR láº¥y thÃªm thÃ´ng tin khoanh trÃ²n / gáº¡ch chÃ¢n
    ocr_text = "\n".join(ocr_blocks)

    return r0_r1, r3, mo_ta, dan_chieu, ocr_text


def build_kpcs_row(r0_r1, r3, mo_ta, dan_chieu, ocr_text, r2_title):
    """
    Mapping Äá»¦ 43 cá»™t KPCS
    """
    return {
        "STT": "",
        "Äá»‘i tÆ°á»£ng Ä‘Æ°á»£c KT": "",
        "Sá»‘ vÄƒn báº£n": "",
        "NgÃ y, thÃ¡ng, nÄƒm ban hÃ nh (mm/dd/yyyy)": "",
        "TÃªn ÄoÃ n kiá»ƒm toÃ¡n": "",
        "Sá»‘ hiá»‡u rá»§i ro": "",
        "Sá»‘ hiá»‡u kiá»ƒm soÃ¡t": "",
        "Nghiá»‡p vá»¥ (R0)": r0_r1,
        "Quy trÃ¬nh/hoáº¡t Ä‘á»™ng con (R1)": r0_r1,
        "TÃªn phÃ¡t hiá»‡n (R2)": r2_title,
        "Chi tiáº¿t phÃ¡t hiá»‡n (R3)": r3,
        "Dáº«n chiáº¿u": dan_chieu,
        "MÃ´ táº£ chi tiáº¿t phÃ¡t hiá»‡n": mo_ta,
        "CIF KhÃ¡ch hÃ ng/bÃºt toÃ¡n": "",
        "TÃªn khÃ¡ch hÃ ng": "",
        "Loáº¡i KH": "",
        "Sá»‘ phÃ¡t hiá»‡n/sá»‘ máº«u chá»n": "",
        "DÆ° ná»£ sai pháº¡m": "",
        "Sá»‘ tiá»n tá»•n tháº¥t": "",
        "Sá»‘ tiá»n cáº§n thu há»“i": "",
        "TrÃ¡ch nhiá»‡m trá»±c tiáº¿p": "",
        "TrÃ¡ch nhiá»‡m quáº£n lÃ½": "",
        "Xáº¿p háº¡ng rá»§i ro": "",
        "Xáº¿p háº¡ng kiá»ƒm soÃ¡t": "",
        "NguyÃªn nhÃ¢n": ocr_text,
        "áº¢nh hÆ°á»Ÿng": ocr_text,
        "Kiáº¿n nghá»‹": ocr_text,
        "Loáº¡i/nhÃ³m nguyÃªn nhÃ¢n": "",
        "Loáº¡i/nhÃ³m áº£nh hÆ°á»Ÿng": "",
        "Loáº¡i/nhÃ³m kiáº¿n nghá»‹": "",
        "Chá»§ thá»ƒ kiáº¿n nghá»‹": "",
        "Káº¿ hoáº¡ch thá»±c hiá»‡n": "",
        "TrÃ¡ch nhiá»‡m thá»±c hiá»‡n": "",
        "ÄÆ¡n vá»‹ thá»±c hiá»‡n KPCS": "",
        "ÄVKD, AMC, Há»™i sá»Ÿ": "",
        "NgÆ°á»i phÃª duyá»‡t": "",
        "Ã kiáº¿n cá»§a Ä‘Æ¡n vá»‹": "",
        "Má»©c Ä‘á»™ Æ°u tiÃªn hÃ nh Ä‘á»™ng": "",
        "Thá»i háº¡n hoÃ n thÃ nh": "",
        "ÄÃ£ kháº¯c phá»¥c": "",
        "NgÃ y Ä‘Ã£ KPCS": "",
        "CBKT (MÃ£ CBKT-Há» tÃªn)": ""
    }


def process_word_to_kpcs(doc_file):
    """
    Pipeline tá»« Word â†’ OCR â†’ Mapping 43 cá»™t
    """
    doc = docx.Document(doc_file)

    paragraphs = extract_word_paragraphs(doc)
    images = extract_images_from_word(doc)
    ocr_blocks = run_ocr_on_images(images)

    r0_r1, r3, mo_ta, dan_chieu, ocr_text = extract_4_regions(paragraphs, ocr_blocks)

    # tÃ¬m tiÃªu Ä‘á» dÃ²ng 1.1 / 2.1 / 3.1
    r2_title = ""
    for p in paragraphs:
        if re.match(r"\d+\.\d+", p):
            r2_title = extract_r2_from_heading(p)
            break

    row = build_kpcs_row(r0_r1, r3, mo_ta, dan_chieu, ocr_text, r2_title)

    return pd.DataFrame([row])


# ===========================================
# =========== STREAMLIT UI ==================
# ===========================================

st.title("ğŸ“˜ TRÃCH 4 VÃ™NG & MAPPING 43 Cá»˜T KPCS â€“ FULL FINAL VERSION")

uploaded = st.file_uploader("Táº£i file Word (.docx)", type=["docx"])

if uploaded:
    st.success("File Ä‘Ã£ táº£i. Nháº¥n xá»­ lÃ½.")

    if st.button("ğŸ”¥ Xá»¬ LÃ FILE WORD â†’ EXCEL KPCS"):
        df = process_word_to_kpcs(uploaded)

        st.subheader("ğŸ¯ Báº£ng káº¿t quáº£ 43 cá»™t KPCS")
        st.dataframe(df, use_container_width=True)

        # Xuáº¥t Excel
        output = io.BytesIO()
        df.to_excel(output, index=False, sheet_name="KPCS")
        st.download_button(
            label="ğŸ“¥ Táº£i xuá»‘ng Excel KPCS",
            data=output.getvalue(),
            file_name="KPCS_output.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

